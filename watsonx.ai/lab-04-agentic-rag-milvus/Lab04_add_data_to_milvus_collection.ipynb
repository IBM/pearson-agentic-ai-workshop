{"metadata": {"kernelspec": {"display_name": "Python 3.11", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "!pip install langchain_core==0.3.75 langchain_huggingface==0.3.1 langchain-community sentence-transformers\n!pip install torch torchvision --upgrade", "metadata": {"id": "52336261-d661-41a1-b4aa-6f18036f3840"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "!pip install ibm-watson-studio-lib ", "metadata": {"id": "81e59a9a-bb39-49ed-989e-1b8fc409057c"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: ibm-watson-studio-lib in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.1.1)\n"}], "execution_count": 5}, {"cell_type": "code", "source": "import os\n# import toml\n\nfrom pymilvus import connections\nfrom pymilvus import Collection, utility, connections, FieldSchema, CollectionSchema, DataType\n\nimport ibm_boto3\nfrom ibm_botocore.client import Config, ClientError\n\nfrom langchain_huggingface import HuggingFaceEmbeddings  # Updated import\n\nfrom dotenv import load_dotenv\n\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='c0685463-22dc-4c40-a870-7b47b3dd01be', project_access_token='p-2+hkUcpNdzw5q/8owbqZ+89Q==;NYGAhLMdsfR8Xmx3KeaJ8A==:QLXIs7rOqdY7iUXl6rm//Tmz1x6zD1bARUhhr8pOoQHlbi59Fz+y0AqF9IU3YQX8uaTAM1p19Ei5DpCdC3LfeLCGaEnsaFgswg==')\npc = project.project_context\n\nfrom ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space({'token':'p-2+hkUcpNdzw5q/8owbqZ+89Q==;NYGAhLMdsfR8Xmx3KeaJ8A==:QLXIs7rOqdY7iUXl6rm//Tmz1x6zD1bARUhhr8pOoQHlbi59Fz+y0AqF9IU3YQX8uaTAM1p19Ei5DpCdC3LfeLCGaEnsaFgswg=='})\n", "metadata": {"id": "dace7d2f-9d40-40c4-880d-e54799c4a853"}, "outputs": [], "execution_count": 26}, {"cell_type": "code", "source": "", "metadata": {"id": "112eba51-e79d-48d2-b416-b052ab195a8e"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## Load connections information from the project", "metadata": {"id": "b1e8463d-6e27-4792-8b56-93aac594d21e"}}, {"cell_type": "code", "source": "# list your connections\nwslib.list_connections()", "metadata": {"id": "b0b266b4-927e-4b5c-bb28-bd3956414826"}, "outputs": [{"execution_count": 27, "output_type": "execute_result", "data": {"text/plain": "[{'name': 'cos-3100014vn6',\n  'description': None,\n  'asset_id': '2bda8a2a-df89-472d-ade3-72b788943b52',\n  'asset_type': 'connection',\n  'tags': None},\n {'name': 'milvus-inst-01',\n  'description': None,\n  'asset_id': 'caae5f3c-72e2-495f-a6e1-229e0f3ef0e3',\n  'asset_type': 'connection',\n  'tags': None}]"}, "metadata": {}}], "execution_count": 27}, {"cell_type": "code", "source": "# make sure you use the right connection name for presto\nmilvus_conn = wslib.get_connection('milvus-inst-01')\ncos_conn = wslib.get_connection('cos-3100014vn6')", "metadata": {"id": "e7f238bd-816f-4048-96de-4709c2ac9a01"}, "outputs": [], "execution_count": 28}, {"cell_type": "markdown", "source": "## Load env.txt file with configuration", "metadata": {"id": "1d8a1c4f-4c75-424a-b3b0-432f9e6be5fa"}}, {"cell_type": "code", "source": "with open('.env_all', 'wb') as env_file:\n    env_file.write(wslib.load_data('env.txt').read())\n# environmental variables store credentials and configuration\nload_dotenv('.env_all')", "metadata": {"id": "d978cf61-ba78-4891-9590-6f8d299966b5"}, "outputs": [{"execution_count": 29, "output_type": "execute_result", "data": {"text/plain": "True"}, "metadata": {}}], "execution_count": 29}, {"cell_type": "markdown", "source": "## COS Resource", "metadata": {"id": "67f8002e-06e3-42da-b5fd-d2835d6e7322"}}, {"cell_type": "code", "source": "# Constants for IBM COS values\nCOS_ENDPOINT = f\"https://{cos_conn['url']}\"\nCOS_API_KEY_ID = cos_conn['api_key']\nCOS_INSTANCE_CRN = cos_conn['resource_instance_id']", "metadata": {"id": "b13f66e8-38a9-43d9-9128-2a70f94fa41c"}, "outputs": [], "execution_count": 51}, {"cell_type": "markdown", "source": "### make sure that COS_ENDPOINT is the same as for buckets and the same for all buckets, if not -> replace", "metadata": {}}, {"cell_type": "code", "source": "print(COS_ENDPOINT)\n# COS_ENDPOINT = \"enter https-prepended endpoint and uncomment\"", "metadata": {"id": "276a87be-8e7d-47f4-a758-f840811ceb5b"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "https://s3.ca-tor.cloud-object-storage.appdomain.cloud\n"}], "execution_count": 12}, {"cell_type": "code", "source": "# Create client\ncos_resource = ibm_boto3.resource(\"s3\",\n    ibm_api_key_id=COS_API_KEY_ID,\n    ibm_service_instance_id=COS_INSTANCE_CRN,\n    config=Config(signature_version=\"oauth\"),\n    endpoint_url=COS_ENDPOINT\n)\n", "metadata": {"id": "75c174e3-22df-492f-9814-22bd4cd76dac"}, "outputs": [], "execution_count": 52}, {"cell_type": "markdown", "source": "## For text splitting and embedding", "metadata": {}}, {"cell_type": "code", "source": "# COS buckets \nINPUT_BUCKET=\"inputdocs\"\nCOS_FOLDER = \"inputdoc\"\n# # parameters for milvus ingestion \n# SIMILARITY_METRIC=\"L2\"\n# SENTENCE_TRANSFORMER = \"sentence-transformers/all-MiniLM-L6-v2\"\n# TEXT_SPLITTER_CHUNK_SIZE=1000\n# TEXT_SPLITTER_CHUNK_OVERLAP=200\n# TEXT_SPLITTER_SEPARATORS='[\" \\n\", \"\\n\"]'\n# TEXT_REPLACEMENTS='{\"\u2714\": \"ok\"}'\n# TEXT_SPLITTER_TYPE=\"RecursiveCharacterTextSplitter\"", "metadata": {"id": "a81d51b7-9111-47da-9c6f-9a40ad143478"}, "outputs": [], "execution_count": 74}, {"cell_type": "code", "source": "embeddings_model_name = os.getenv(\"SENTENCE_TRANSFORMER\")\nchunk_size = int(os.getenv(\"TEXT_SPLITTER_CHUNK_SIZE\"))\nchunk_overlap = int(os.getenv(\"TEXT_SPLITTER_CHUNK_OVERLAP\"))\n\n# TEXT - SPLITTER RELATED\ntext_splitter_type = os.getenv(\"TEXT_SPLITTER_TYPE\")\n# to define text splitter incl. text splitter separators (defined in the environment variables)\n# json string\ntext_splitter_separators = os.getenv(\"TEXT_SPLITTER_SEPARATORS\")\ntext_replacements = os.getenv(\"TEXT_REPLACEMENTS\")\n\nsimilarity_metric = os.getenv(\"SIMILARITY_METRIC\")\n\nINPUT_BUCKET = os.environ[\"INPUT_BUCKET\"]", "metadata": {"id": "15635fef-5a73-4856-ba44-a1175e6decb5"}, "outputs": [], "execution_count": 33}, {"cell_type": "code", "source": "INPUT_BUCKET", "metadata": {"id": "886751af-a209-4376-9735-02c8f4387835"}, "outputs": [{"execution_count": 54, "output_type": "execute_result", "data": {"text/plain": "'inputdocs'"}, "metadata": {}}], "execution_count": 54}, {"cell_type": "code", "source": "# embeddings function - TO SELECT FUNCTION and PARAMETERS\nembeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)", "metadata": {"id": "625a6d22-f0b3-4bc6-8d4a-f1978f3bbfdb"}, "outputs": [], "execution_count": 42}, {"cell_type": "markdown", "source": "## For milvus connection", "metadata": {}}, {"cell_type": "code", "source": "# Authentication for Milvus within wx.data\nhost = milvus_conn[\"host\"]\nport = milvus_conn[\"port\"]\npassword = milvus_conn[\"password\"]\nuser = milvus_conn[\"username\"]\n\nmv_collection = os.environ[\"MV_COLLECTION_NAME\"]\n", "metadata": {"id": "c8db4731-194c-4420-aa4a-ccd374a32c4b"}, "outputs": [], "execution_count": 43}, {"cell_type": "code", "source": "connection_args={\n               'host':host,\n               'port':port,\n               'user': user,\n               'password': password,\n                'secure': True\n}", "metadata": {"id": "358e9d07-9108-41de-aca0-f98a1a422e8f"}, "outputs": [], "execution_count": 44}, {"cell_type": "code", "source": "RecursiveCharacterTextSplitter", "metadata": {"id": "dc72cd61-82c0-4e94-8e8d-66adc0624e88"}, "outputs": [{"execution_count": 71, "output_type": "execute_result", "data": {"text/plain": "langchain_text_splitters.character.RecursiveCharacterTextSplitter"}, "metadata": {}}], "execution_count": 71}, {"cell_type": "markdown", "source": "# 1. Load and split documents", "metadata": {}}, {"cell_type": "code", "source": "import json\nimport os\nimport posixpath\n\nfrom ibm_botocore.client import ClientError\n\nfrom langchain.document_loaders import (\n    PyPDFLoader,\n    Docx2txtLoader,\n    TextLoader,\n    UnstructuredHTMLLoader,\n)\nfrom langchain.text_splitter import (\n    CharacterTextSplitter,\n    RecursiveCharacterTextSplitter,\n)\n\n# dictionary with text splitter classes\ntext_splitter_type_dict = {\n    \"CharacterTextSplitter\": CharacterTextSplitter,\n    \"RecursiveCharacterTextSplitter\": RecursiveCharacterTextSplitter,\n}\n\n# dictionary with available document loaders\n_document_loaders_dict = {\n    \"docx\": Docx2txtLoader,\n    \"html\": UnstructuredHTMLLoader,\n    \"pdf\": PyPDFLoader,\n    \"csv\": TextLoader,\n    \"txt\": TextLoader,\n}\n\ndef get_bucket_contents(cur_conn, bucket_name):\n    \"\"\"\n    function to get the list of files from the given bucket\n    \"\"\"\n    items_list = []\n    print(\"Retrieving bucket contents from:{0}\".format(bucket_name))\n    try:\n        files = cur_conn.Bucket(bucket_name).objects.all()\n        print(files)\n        for file in files:\n            items_list.append(\"{0}\".format(file.key))\n    except ClientError as be:\n        print(\"CLIENT ERROR: {0}\".format(be))\n    except Exception as e:\n        print(\"Unable to retrieve bucket contents: {0}\".format(e))\n    print(items_list)\n    return items_list\n\ndef get_item(cur_conn, bucket_name, item_name):\n    \"\"\"\n    get file contents of a particular file:\n    - based on bucket_name and item_name\n\n    \"\"\"\n    print(\n        \"Retrieving item from bucket: {0}, key: {1}\".format(\n            bucket_name, item_name\n        )\n    )\n    try:\n        file = cur_conn.Object(bucket_name, item_name).get()\n        print(\"File Contents retrieved\")\n        print(file)\n        return file\n    except ClientError as be:\n        print(\"CLIENT ERROR: {0}\".format(be))\n    except Exception as e:\n        print(\"Unable to retrieve file contents: {0}\".format(e))\n\ndef _save_doc_linux(cur_conn, bucket_name, doc_path, tmp_location):\n    \"\"\"Save file from COS to temp location locally\"\"\"\n    bytes_obj = get_item(cur_conn, bucket_name, doc_path)[\"Body\"].read()\n    with open(tmp_location, \"wb\") as f:\n        f.write(bytes_obj)\n\n\ndef _replace_characters(text_replacements, init_text: str) -> str:\n    \"\"\"\n    Replaces characters in the init_text based on text_replacements that contains mapping {\"old_char\": \"new_char\"}.\n    Returns text with the replaced character\n    \"\"\"\n    replace_json_dict = json.loads(text_replacements)\n    output_text = init_text\n    for old_char, new_char in replace_json_dict.items():\n        output_text = output_text.replace(old_char, new_char)\n    return output_text\n\n\ndef load_split_cos_docs(\n    cur_conn,\n    bucket_name,\n    chunk_size,\n    chunk_overlap,\n    text_splitter_type,\n    text_splitter_separators,\n    text_replacements,\n):\n    \"\"\"\n    Load and split txt, pdf and doc documents from bucket on COS, where:\n    - cur_conn is connection established to COS\n    - bucket_name is the name of the bucket with documents to load and split\n    - chunk size is the size of text to split by\n    - chunk overlap is the number of characters to overlap between chunks\n    By default it will use original language, to translate to english you need to set translate to True\n    \"\"\"\n    # list to save all docs into a list\n    split_loaded_docs = list()\n    temp_folder = os.path.join(\".\", \"temp\")\n\n    if text_splitter_separators is not None and text_splitter_separators != \"\":\n        text_splitter_separators = json.loads(text_splitter_separators, strict=False)\n\n    # location for temp files\n    bucket_contents = get_bucket_contents(cur_conn, bucket_name)\n    print(bucket_contents)\n    # defining the splitter\n    if text_splitter_type in text_splitter_type_dict:\n        print(f\"Using {text_splitter_type}\")\n        # free text\n        if (\n            isinstance(text_splitter_separators, list)\n            and len(text_splitter_separators) > 0\n        ):\n            text_splitter = text_splitter_type_dict[text_splitter_type](\n                chunk_size=chunk_size,\n                chunk_overlap=chunk_overlap,\n                separators=text_splitter_separators,\n            )\n            print(\n                f\"Specified separators for the text splitter {text_splitter_separators}\"\n            )\n        else:\n            text_splitter = text_splitter_type_dict[text_splitter_type](\n                chunk_size=chunk_size, chunk_overlap=chunk_overlap\n            )\n            print(\n                \"Separators for text splitters are either not specified or specified incorrectly\"\n            )\n    else:\n        print(f\"Text splitter of type {text_splitter_type} is not supported\")\n\n    # going through files\n    print(\"Looping through bucket contents\")\n    for doc_path_num, doc_path in enumerate(bucket_contents):\n        # to check only files within project sources\n        sources_folder_path = posixpath.join(COS_FOLDER)\n        if sources_folder_path not in doc_path:\n            continue\n        print(f\"Processing {doc_path}\")\n        cur_doc_format = doc_path.split(\".\")[-1].lower()\n        # to create temp folder if it doesn't exist\n        if not os.path.exists(temp_folder):\n            os.mkdir(temp_folder)\n        tmp_location = os.path.join(temp_folder, doc_path.split(\"/\")[-1])\n        print(f\"Attempting to load {doc_path}\")\n        # check for formatting\n        if cur_doc_format in _document_loaders_dict:\n            # to load document\n            _save_doc_linux(cur_conn, bucket_name, doc_path, tmp_location)\n            doc_loader = _document_loaders_dict[cur_doc_format](tmp_location)\n            loaded_docs = doc_loader.load()\n        else:\n            logger.warning(\n                f\"Data in {doc_path} is not supported, accepted formats are {_document_loaders_dict.keys()}\"\n            )\n            continue\n        print(f\"Successfully loaded {doc_path}\")\n\n        # to change metadata of loaded documents to include only filename for the source\n        # replace strings based on the input json\n        for loaded_doc in loaded_docs:\n            # to change metadata of loaded documents to include only filename for the source\n            loaded_doc.metadata[\"source\"] = doc_path.split(\"/\")[-1]\n            # to replace characters in page_content according to dict stored in TEXT_REPLACEMENTS\n            if text_replacements != \"\" and text_replacements is not None:\n                loaded_doc.page_content = _replace_characters(\n                    text_replacements, loaded_doc.page_content\n                )\n        # to split documents\n        print(f\"Splitting docs loaded from {doc_path}\")\n        splitted_docs = text_splitter.split_documents(loaded_docs)\n        # to add current document to total list\n        split_loaded_docs.extend(splitted_docs)\n        if os.path.exists(tmp_location):\n            os.remove(tmp_location)\n            print(f\"File {tmp_location} was removed\")\n    # after loop through COS documents ended\n    print(\"Documents from Cloud Object Storage are loaded and splitted\")\n    return {\"splitted_loaded_docs\": split_loaded_docs}\n", "metadata": {"id": "96147576-087e-41b2-8789-9614a7539f9f"}, "outputs": [], "execution_count": 78}, {"cell_type": "code", "source": "splitted_docs = load_split_cos_docs(\n        cos_resource, INPUT_BUCKET, chunk_size, chunk_overlap, text_splitter_type, text_splitter_separators, text_replacements\n        )", "metadata": {"id": "f05d9950-e561-432b-a860-7de0c7cb2253"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Retrieving bucket contents from:inputdocs\ns3.Bucket.objectsCollection(s3.Bucket(name='inputdocs'), s3.ObjectSummary)\n['Simmons-Bank-Code-of-Ethics.pdf', 'inputdoc/pie_recipe.pdf', 'paper_flowers.pdf']\n['Simmons-Bank-Code-of-Ethics.pdf', 'inputdoc/pie_recipe.pdf', 'paper_flowers.pdf']\nUsing RecursiveCharacterTextSplitter\nSpecified separators for the text splitter [' \\n', '\\n']\nLooping through bucket contents\nProcessing inputdoc/pie_recipe.pdf\nAttempting to load inputdoc/pie_recipe.pdf\nRetrieving item from bucket: inputdocs, key: inputdoc/pie_recipe.pdf\nFile Contents retrieved\n{'ResponseMetadata': {'RequestId': '31b0ff5b-6c70-43a0-8c51-b8d7e7822cfc', 'HostId': '', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 25 Oct 2025 11:20:29 GMT', 'x-clv-request-id': '31b0ff5b-6c70-43a0-8c51-b8d7e7822cfc', 'server': 'Cleversafe', 'x-clv-s3-version': '2.5', 'accept-ranges': 'bytes', 'x-amz-request-id': '31b0ff5b-6c70-43a0-8c51-b8d7e7822cfc', 'etag': '\"247a65c91848b285b08cf32fe2c55ea8\"', 'content-type': 'application/pdf', 'last-modified': 'Sat, 25 Oct 2025 11:19:04 GMT', 'content-length': '348739'}, 'RetryAttempts': 0}, 'AcceptRanges': 'bytes', 'LastModified': datetime.datetime(2025, 10, 25, 11, 19, 4, tzinfo=tzutc()), 'ContentLength': 348739, 'ETag': '\"247a65c91848b285b08cf32fe2c55ea8\"', 'ContentType': 'application/pdf', 'Metadata': {}, 'Body': <ibm_botocore.response.StreamingBody object at 0x7fab2aba9000>}\nSuccessfully loaded inputdoc/pie_recipe.pdf\nSplitting docs loaded from inputdoc/pie_recipe.pdf\nFile ./temp/pie_recipe.pdf was removed\nDocuments from Cloud Object Storage are loaded and splitted\n"}], "execution_count": 79}, {"cell_type": "code", "source": "sources = []\npages = []\ndocs = []\nfor splitted_doc in splitted_docs['splitted_loaded_docs']:\n    sources.append(splitted_doc.metadata['source'])\n    pages.append(splitted_doc.metadata['page'])\n    docs.append(splitted_doc.page_content)", "metadata": {"id": "b9505ae3-bd82-4602-b177-6c0dec79c9d2"}, "outputs": [], "execution_count": 80}, {"cell_type": "code", "source": "splitted_docs", "metadata": {"id": "374e5d99-956d-44af-8c68-cbeab0cdab57"}, "outputs": [{"execution_count": 81, "output_type": "execute_result", "data": {"text/plain": "{'splitted_loaded_docs': [Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Curtis Stone\u2019s Meat Pie Recipe \\n \\nServes 6 | Prep Time: 30 minutes | Cook Time: 1 hour and 45 minutes \\n \\nIngredients: \\n \\n\\uf0b7 1 \u00bc cup extra-virgin olive oil  \\n\\uf0b7 1 small yellow onion, finely chopped  \\n\\uf0b7 1 celery stalk, finely chopped  \\n\\uf0b7 1 small carrot, finely chopped  \\n\\uf0b7 2 ounces prosciutto di Parma (about 5 \\nslices), finely chopped  \\n\\uf0b7 1 \u00be pounds ground beef chuck \\n\\uf0b7 Kosher salt and freshly ground black \\npepper  \\n\\uf0b7 3 ounces chicken livers (about 3), \\nrinsed, cleaned, and finely chopped  \\n\\uf0b7 2 tablespoons tomato paste  \\n\\uf0b7 \u215b teaspoon ground allspice  \\n\\uf0b7 \u00bd cup dry white wine \\n\\uf0b7 \u00bd cup whole milk  \\n\\uf0b7 2 tablespoons all-purpose flour  \\n\\uf0b7 3 cups low-sodium beef broth \\n \\nTo assemble the pies: \\n\\uf0b7 All-purpose flour, for dusting \\n\\uf0b7 Buttery Pastry Dough (see recipe \\nbelow), shaped into 12 disks and \\nchilled \\n\\uf0b7 1 large egg \\n\\uf0b7 1 tablespoon heavy cream  \\n \\nTo make the filling: \\n \\n1. Heat a large heavy pot over medium-high heat. Add the oil, then add the onion, celery,'),\n  Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='chilled \\n\\uf0b7 1 large egg \\n\\uf0b7 1 tablespoon heavy cream  \\n \\nTo make the filling: \\n \\n1. Heat a large heavy pot over medium-high heat. Add the oil, then add the onion, celery, \\nand carrot and saut\u00e9 for about 5 minutes, or until the vegetables are tender but not browned. \\nAdd the prosciutto and saut\u00e9 for 2 minutes.  \\n \\n2. Crumble the beef into the pot and season with salt and pepper. Cook, stirring with a \\nwooden spoon to break up the beef, for about 5 minutes, or until the meat is just cooked and \\nno longer pink. Add the chicken livers and cook for about 2 minutes, or until the livers are just \\ncooked and no longer pink. Add the tomato paste and allspice and cook, stirring, for about 2 \\nminutes, or until the tomato paste is well blended.  \\n \\n3. Stir in the wine and cook for about 2 minutes, or until it evaporates completely. Reduce the \\nheat to medium, add the milk, and cook, stirring occasionally, for about 2 minutes, or until the'),\n  Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='3. Stir in the wine and cook for about 2 minutes, or until it evaporates completely. Reduce the \\nheat to medium, add the milk, and cook, stirring occasionally, for about 2 minutes, or until the \\nmilk has reduced by three-fourths and the sauce is thick and creamy. Sprinkle the flour over \\nthe mixture and cook for about 1 minute, stirring constantly, or until well blended. \\n \\n4. Add the broth, bring to a simmer, and simmer for 25 minutes, or until the liquid has \\nthickened and reduced by one-fourth. Season with salt and pepper. Set the mixture aside to \\ncool. (You should have about 4 \u00bd cups filling.)'),\n  Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='To assemble and bake the pies:  \\n \\n5. Position a rack on the lowest rung of the oven and set a baking sheet on the rack. Preheat \\nthe oven to 400\u00b0F. (Being close to the source of heat will help the bottom crusts bake and \\nbrown properly.)  \\n \\n6. On a floured work surface, roll out 1 disk of dough to a 6-inch round about \u215b inch thick. \\nLine a 5-inch disposable aluminum pie pan with the dough. Repeat with 5 more dough balls \\nand pie pans. Divide the filling among the pans, using about \u00be cup filling per pie.  \\n \\n7. Roll out the remaining 6 dough pieces to 6-inch rounds and lay them over the filling. Trim \\nthe dough overhang to \u00bd inch. Pinch the bottom and top crusts together to seal and fold \\nthem under. Make a hole in the center of each top crust, if desired.  \\n \\n8. In a small bowl, whisk the egg and cream to blend. Using a pastry brush, lightly brush the \\ntops of the pies with the egg-cream mixture.'),\n  Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='8. In a small bowl, whisk the egg and cream to blend. Using a pastry brush, lightly brush the \\ntops of the pies with the egg-cream mixture.  \\n \\n9. Place the pies on the preheated baking sheet in the oven and bake for about 40 minutes, \\nor until the crust is deep golden and the filling is bubbling. If the crust begins to brown before \\nthe filling bubbles, tent the pies with foil. Let the pies cool on a wire rack until warm before \\nserving. \\n \\n \\nButtery Pastry Dough  \\n \\nPrep Time: 10 minutes, plus 30 minutes chilling time   \\n \\nMakes: Enough for 12 individual meat pies \\n \\nIngredients: \\n\\uf0b7 2 \u00bd cups all-purpose flour \\n\\uf0b7 1 tablespoon sugar \\n\\uf0b7 \u00bd teaspoon fine sea salt or table salt \\n\\uf0b7 \u00bd pound (2 sticks) cold unsalted butter, cut into \u00bd-\\ninch cubes  \\n\\uf0b7 About \u2153 cup ice water  \\n \\n \\n \\n \\nMethod: \\n1. In a food processor, combine the flour, sugar, and salt and pulse to blend. Add the butter \\nand pulse about 10 times, or until the butter is in pea-size pieces; do not overprocess.'),\n  Document(metadata={'producer': 'Microsoft\u00ae Word 2016', 'creator': 'Microsoft\u00ae Word 2016', 'creationdate': '2021-02-05T12:37:19-08:00', 'author': 'Stella, Gavin (RNA/MK-MAB)', 'moddate': '2021-02-05T12:37:19-08:00', 'source': 'pie_recipe.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Method: \\n1. In a food processor, combine the flour, sugar, and salt and pulse to blend. Add the butter \\nand pulse about 10 times, or until the butter is in pea-size pieces; do not overprocess. \\nWhile pulsing the processor, add \u2153 cup of the ice water, then pulse just until moist \\nclumps of dough form, adding more water 1 tablespoon at a time if necessary.  \\n \\n2. Transfer the dough to a work surface and divide it in half. Divide each piece of dough into \\n6 pieces and shape into disks. Wrap individually in plastic wrap and refrigerate for at least \\n30 minutes before rolling out.')]}"}, "metadata": {}}], "execution_count": 81}, {"cell_type": "markdown", "source": "# 2. Milvus", "metadata": {}}, {"cell_type": "markdown", "source": "## Connect", "metadata": {}}, {"cell_type": "code", "source": "connections.connect(\nalias='default',\n**connection_args\n)", "metadata": {"id": "fb905b4e-b8c2-4ab3-8b6e-fa1345b722c9"}, "outputs": [], "execution_count": 82}, {"cell_type": "code", "source": "utility.has_collection(mv_collection)", "metadata": {"id": "b0839691-41be-45a0-95de-effcdb71756d"}, "outputs": [{"execution_count": 83, "output_type": "execute_result", "data": {"text/plain": "False"}, "metadata": {}}], "execution_count": 83}, {"cell_type": "markdown", "source": "## To drop collection if exists", "metadata": {}}, {"cell_type": "code", "source": "if utility.has_collection(mv_collection): # check if collection exists\n    utility.drop_collection(mv_collection)", "metadata": {"id": "f8a6202a-7db7-410f-a55d-1c71baf7eef9"}, "outputs": [], "execution_count": 84}, {"cell_type": "markdown", "source": "## To create a new collection\n> you can update schema naming to correspond to your requirements", "metadata": {}}, {"cell_type": "code", "source": "fields = [\n    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n    FieldSchema(name=\"text_embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),  # Assuming 384-dim vectors\n    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=500),\n    FieldSchema(name=\"page\", dtype=DataType.INT64),\n    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),  # Storing original content as well\n]\nschema = CollectionSchema(fields)\ncollection = Collection(name=mv_collection, schema=schema)", "metadata": {"id": "12230f60-05d0-41b3-b102-dfee792b1891"}, "outputs": [], "execution_count": 85}, {"cell_type": "code", "source": "print(collection.schema.fields)", "metadata": {"id": "fa6592d3-866e-4a62-9ac2-1de5a6143bf3"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'text_embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}, {'name': 'title', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 500}}, {'name': 'page', 'description': '', 'type': <DataType.INT64: 5>}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}]\n"}], "execution_count": 86}, {"cell_type": "markdown", "source": "## To insert documents into collection, create index and load data into memory", "metadata": {}}, {"cell_type": "code", "source": "# Convert documents into vector embeddings\ndoc_embeddings = embeddings.embed_documents(docs)\n\n# Insert documents and embeddings into Milvus\ncollection.insert([doc_embeddings, sources, pages, docs]) ", "metadata": {"id": "84b4f2ae-ee88-4344-a677-7d016591c2b3"}, "outputs": [{"execution_count": 87, "output_type": "execute_result", "data": {"text/plain": "(insert count: 6, delete count: 0, upsert count: 0, timestamp: 461738156283920387, success count: 6, err count: 0"}, "metadata": {}}], "execution_count": 87}, {"cell_type": "code", "source": "# create index\nindex_params = {\n    \"index_type\": \"IVF_FLAT\",  # Can also use \"IVF_PQ\", \"HNSW\", etc.\n    \"metric_type\": similarity_metric,       # L2 for Euclidean distance, or use \"IP\" for Inner Product\n    \"params\": {\"nlist\": 110},  # nlist is a hyperparameter for clustering / corresponds to cca 800 vectors\n}\n\ncollection.create_index(field_name=\"text_embedding\", index_params=index_params)", "metadata": {"id": "4ff47033-df83-4bcf-a2bb-b8011e90efca"}, "outputs": [{"execution_count": 88, "output_type": "execute_result", "data": {"text/plain": "Status(code=0, message=)"}, "metadata": {}}], "execution_count": 88}, {"cell_type": "code", "source": "# Load data into memory (optional but recommended for larger datasets)\ncollection.load()", "metadata": {"id": "199b5358-cef9-48b3-ae9d-20d235c90aa4"}, "outputs": [], "execution_count": 89}, {"cell_type": "markdown", "source": "## To perform semantic search", "metadata": {}}, {"cell_type": "code", "source": "cur_query=\"top ingredients in Meat Pie Recipe\"\nsearch_params = {\"metric_type\": similarity_metric, \"params\": {\"nprobe\": 10}}\nquery_result = collection.search(\n    [embeddings.embed_query(cur_query)], \n    \"text_embedding\", \n    search_params, \n    limit=5, \n    output_fields=[\"title\", \"page\", \"text\"])\n# Print the query result\nfor entity in query_result[0]:\n    print(entity)", "metadata": {"id": "33187800-dbb9-44ff-b541-9c38df2cacd0"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "id: 461692709396379109, distance: 0.5376728773117065, entity: {'title': 'pie_recipe.pdf', 'page': 0, 'text': 'Curtis Stone\u2019s Meat Pie Recipe \\n \\nServes 6 | Prep Time: 30 minutes | Cook Time: 1 hour and 45 minutes \\n \\nIngredients: \\n \\n\\uf0b7 1 \u00bc cup extra-virgin olive oil  \\n\\uf0b7 1 small yellow onion, finely chopped  \\n\\uf0b7 1 celery stalk, finely chopped  \\n\\uf0b7 1 small carrot, finely chopped  \\n\\uf0b7 2 ounces prosciutto di Parma (about 5 \\nslices), finely chopped  \\n\\uf0b7 1 \u00be pounds ground beef chuck \\n\\uf0b7 Kosher salt and freshly ground black \\npepper  \\n\\uf0b7 3 ounces chicken livers (about 3), \\nrinsed, cleaned, and finely chopped  \\n\\uf0b7 2 tablespoons tomato paste  \\n\\uf0b7 \u215b teaspoon ground allspice  \\n\\uf0b7 \u00bd cup dry white wine \\n\\uf0b7 \u00bd cup whole milk  \\n\\uf0b7 2 tablespoons all-purpose flour  \\n\\uf0b7 3 cups low-sodium beef broth \\n \\nTo assemble the pies: \\n\\uf0b7 All-purpose flour, for dusting \\n\\uf0b7 Buttery Pastry Dough (see recipe \\nbelow), shaped into 12 disks and \\nchilled \\n\\uf0b7 1 large egg \\n\\uf0b7 1 tablespoon heavy cream  \\n \\nTo make the filling: \\n \\n1. Heat a large heavy pot over medium-high heat. Add the oil, then add the onion, celery,'}\nid: 461692709396379113, distance: 0.8786635994911194, entity: {'title': 'pie_recipe.pdf', 'page': 1, 'text': '8. In a small bowl, whisk the egg and cream to blend. Using a pastry brush, lightly brush the \\ntops of the pies with the egg-cream mixture.  \\n \\n9. Place the pies on the preheated baking sheet in the oven and bake for about 40 minutes, \\nor until the crust is deep golden and the filling is bubbling. If the crust begins to brown before \\nthe filling bubbles, tent the pies with foil. Let the pies cool on a wire rack until warm before \\nserving. \\n \\n \\nButtery Pastry Dough  \\n \\nPrep Time: 10 minutes, plus 30 minutes chilling time   \\n \\nMakes: Enough for 12 individual meat pies \\n \\nIngredients: \\n\\uf0b7 2 \u00bd cups all-purpose flour \\n\\uf0b7 1 tablespoon sugar \\n\\uf0b7 \u00bd teaspoon fine sea salt or table salt \\n\\uf0b7 \u00bd pound (2 sticks) cold unsalted butter, cut into \u00bd-\\ninch cubes  \\n\\uf0b7 About \u2153 cup ice water  \\n \\n \\n \\n \\nMethod: \\n1. In a food processor, combine the flour, sugar, and salt and pulse to blend. Add the butter \\nand pulse about 10 times, or until the butter is in pea-size pieces; do not overprocess.'}\nid: 461692709396379112, distance: 1.1343178749084473, entity: {'title': 'pie_recipe.pdf', 'page': 1, 'text': 'To assemble and bake the pies:  \\n \\n5. Position a rack on the lowest rung of the oven and set a baking sheet on the rack. Preheat \\nthe oven to 400\u00b0F. (Being close to the source of heat will help the bottom crusts bake and \\nbrown properly.)  \\n \\n6. On a floured work surface, roll out 1 disk of dough to a 6-inch round about \u215b inch thick. \\nLine a 5-inch disposable aluminum pie pan with the dough. Repeat with 5 more dough balls \\nand pie pans. Divide the filling among the pans, using about \u00be cup filling per pie.  \\n \\n7. Roll out the remaining 6 dough pieces to 6-inch rounds and lay them over the filling. Trim \\nthe dough overhang to \u00bd inch. Pinch the bottom and top crusts together to seal and fold \\nthem under. Make a hole in the center of each top crust, if desired.  \\n \\n8. In a small bowl, whisk the egg and cream to blend. Using a pastry brush, lightly brush the \\ntops of the pies with the egg-cream mixture.'}\nid: 461692709396379110, distance: 1.2525935173034668, entity: {'title': 'pie_recipe.pdf', 'page': 0, 'text': 'chilled \\n\\uf0b7 1 large egg \\n\\uf0b7 1 tablespoon heavy cream  \\n \\nTo make the filling: \\n \\n1. Heat a large heavy pot over medium-high heat. Add the oil, then add the onion, celery, \\nand carrot and saut\u00e9 for about 5 minutes, or until the vegetables are tender but not browned. \\nAdd the prosciutto and saut\u00e9 for 2 minutes.  \\n \\n2. Crumble the beef into the pot and season with salt and pepper. Cook, stirring with a \\nwooden spoon to break up the beef, for about 5 minutes, or until the meat is just cooked and \\nno longer pink. Add the chicken livers and cook for about 2 minutes, or until the livers are just \\ncooked and no longer pink. Add the tomato paste and allspice and cook, stirring, for about 2 \\nminutes, or until the tomato paste is well blended.  \\n \\n3. Stir in the wine and cook for about 2 minutes, or until it evaporates completely. Reduce the \\nheat to medium, add the milk, and cook, stirring occasionally, for about 2 minutes, or until the'}\nid: 461692709396379111, distance: 1.5137324333190918, entity: {'title': 'pie_recipe.pdf', 'page': 0, 'text': '3. Stir in the wine and cook for about 2 minutes, or until it evaporates completely. Reduce the \\nheat to medium, add the milk, and cook, stirring occasionally, for about 2 minutes, or until the \\nmilk has reduced by three-fourths and the sauce is thick and creamy. Sprinkle the flour over \\nthe mixture and cook for about 1 minute, stirring constantly, or until well blended. \\n \\n4. Add the broth, bring to a simmer, and simmer for 25 minutes, or until the liquid has \\nthickened and reduced by one-fourth. Season with salt and pepper. Set the mixture aside to \\ncool. (You should have about 4 \u00bd cups filling.)'}\n"}], "execution_count": 90}, {"cell_type": "code", "source": "", "metadata": {"id": "d59260b2-e4bc-41dc-99eb-cf9c4a4080f9"}, "outputs": [], "execution_count": null}]}