{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "## Prompt Lab Challenge Exercises Notebook", "metadata": {}}, {"cell_type": "markdown", "source": "Welcome to the second prompt lab in the bootcamp series, you should have completed lab 1 and the exercises follow on from those. If you completed all the exercises in Lab 1 you should find most of the exercises here straightforward\n\nThis notebook is a template with all the exercises and indications of what the output should look like if you do a good job with the prompts.\n\nBefore you start you should have a Python environment with the necessary libraries installed as indicated in the intro lab, you will also need a .env file with: \n- your IBM Cloud API key\n- the IBM Cloud regional URL (eg, https://us-south.ml.cloud.ibm.com)\n- the project ID associated with your WatsonX project (required by the WML Python SDK)\n\nIt should take you about 30-45 min to walk through the exercises self paced\n\nGood luck and make sure you compare your answers with the model solutions\n", "metadata": {}}, {"cell_type": "code", "source": "import getpass\nfrom ibm_watsonx_ai import Credentials\nfrom ibm_watsonx_ai import APIClient\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\nfrom ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n", "metadata": {"id": "ff63c6d9-478b-47b4-8570-f5ce0102247d"}, "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "source": "2. Load credentials for Watsonx.ai (note refer to lab explaining how to do this if necessary)\n    - you should have a .env file with your IBM Cloud API key, eg API_KEY=xxx\n    - you should have a .env with the IBM Cloud regional url, eg IBM_CLOUD_URL=https://us-south.ml.cloud.ibm.com\n    - you should have a .env with the associated WatsonX project ID, eg PROJECT_ID=xxx", "metadata": {}}, {"cell_type": "code", "source": "\ncredentials = Credentials(\n    url=\"https://ca-tor.ml.cloud.ibm.com\",\n    api_key=getpass.getpass(\"Please enter your watsonx.ai api key (hit enter): \"),\n)\nproject_id = getpass.getpass(\"Please enter your watsonx.ai project id  (hit enter): \"),", "metadata": {"id": "2689c9de-335a-47d4-a498-6dcb12b926dc"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Please enter your watsonx.ai api key (hit enter):  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nPlease enter your watsonx.ai project id  (hit enter):  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}], "execution_count": 2}, {"cell_type": "code", "source": "api_client = APIClient(credentials=credentials)", "metadata": {"id": "dede6b27-7f30-4ecc-a8af-81142c050aa3"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": "api_client.set.default_project(project_id[0])", "metadata": {"id": "22abe462-1bf8-4a81-96d8-020b0dc1b219"}, "outputs": [{"execution_count": 4, "output_type": "execute_result", "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}], "execution_count": 4}, {"cell_type": "markdown", "source": "Helper function for text generation with the [WML Python SDK](https://ibm.github.io/watson-machine-learning-sdk/foundation_models.html) for foundation models.", "metadata": {}}, {"cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import ModelInference\nfrom ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n\n\ndef send_to_watsonxai(prompts,\n                    model_name=\"mistralai/mistral-small-3-1-24b-instruct-2503\",\n                    decoding_method=\"greedy\",\n                    max_new_tokens=20,\n                    min_new_tokens=1,\n                    temperature=1.0,\n                    repetition_penalty=1.0\n                    ):\n    '''\n   helper function for sending prompts and params to Watsonx.ai\n    \n    Args:  \n        prompts:list list of text prompts\n        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n        temperature:float Watsonx.ai parameter for temperature (range 0>2)\n        repetition_penalty:float Watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n\n    Returns: None\n        prints response\n    '''\n\n    assert not any(map(lambda prompt: len(prompt) < 1, prompts)), \"make sure none of the prompts in the inputs prompts are empty\"\n\n    # # To display example params enter\n    # print(GenParams().get_example_values())\n    \n    # Instantiate parameters for text generation\n    generate_params = {\n        GenParams.DECODING_METHOD: decoding_method,\n        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n        GenParams.TEMPERATURE: temperature,\n        GenParams.TOP_K: 50,\n        GenParams.TOP_P: 1,\n        GenParams.REPETITION_PENALTY: repetition_penalty,\n    }\n\n    # Instantiate a model proxy object to send your requests\n    model_inference = ModelInference(\n        model_id=model_name,\n        params=generate_params,\n        credentials=credentials,\n        project_id=project_id[0]\n    )\n    for prompt in prompts:\n        print( model_inference.generate(prompt))", "metadata": {"id": "745fd451-1b3f-476e-953e-0054d8fa02a1"}, "outputs": [], "execution_count": 16}, {"cell_type": "code", "source": "# mt_model = 'bigscience/mt0-xxl'\n# flanul_model = 'google/flan-ul2'\n# granite_13b_instruct_v2 = 'ibm/granite-13b-instruct-v2'\n# llama2 = \"meta-llama/llama-2-70b-chat\"\n# t5 = \"google/flan-t5-xxl\"", "metadata": {"id": "55c13e6a-3b30-46a3-9a82-a3407d0dc0b5"}, "outputs": [], "execution_count": 7}, {"cell_type": "markdown", "source": "---", "metadata": {}}, {"cell_type": "code", "source": "# Product Review for Questions  1 - 5\nreview = \"\"\"Needed a nice lamp for my bedroom, and this one had \\\nadditional storage and not too high of a price point. \\\nGot it fast.  The string to our lamp broke during the \\\ntransit and the company happily sent over a new one. \\\nCame within a few days as well. It was easy to put \\\ntogether.  I had a missing part, so I contacted their \\\nsupport and they very quickly got me the missing piece! \\\nLumina seems to me to be a great company that cares \\\nabout their customers and products!!\"\"\"", "metadata": {"id": "ada1211b-aa9d-4d61-a56a-4e423eda6fe4"}, "outputs": [], "execution_count": 8}, {"cell_type": "markdown", "source": "#### Q1) write a prompt to return the sentiment of the review\nTarget sentiment = positive", "metadata": {}}, {"cell_type": "code", "source": "#Q1 Code - enter prompt and parameters in this cell\n\nprompt = f\"\"\"\nRead the following product review and classify its sentiment.\n\nReview:\n\\\"\\\"\\\"{review}\\\"\\\"\\\"\n\nAnswer with only one word: Positive or Negative. No explanation\n\"\"\"\n\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "f95d45d5-8cd2-4d1b-bc21-5a6d9513a5cc"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{'model_id': 'mistralai/mistral-small-3-1-24b-instruct-2503', 'model_version': '1.0.0', 'created_at': '2025-10-25T07:50:33.657Z', 'results': [{'generated_text': 'Positive', 'generated_token_count': 2, 'input_token_count': 131, 'stop_reason': 'eos_token'}], 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}, {'message': 'In future implementation, the parameter `parameters.decoding_method` will be ignored and set automatically', 'id': 'param_deprecation'}, {'message': \"This API is legacy. Please consider using '/ml/v1/text/chat' instead.\", 'id': 'api_legacy'}]}}\n"}], "execution_count": 17}, {"cell_type": "markdown", "source": "#### Q2) extract the emotions the reviewer expressed, return answer as a comma separated list\nTarget emotions = satisfied, happy, cared for, great company, product!", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nReview text: '''{review}'''\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "21a44797-460d-46b5-a971-48c02ac47360"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q3) Is the reviewer expressing anger, answer \u201cyes\u201d or \u201cno\u201d \u2013 test with your own example including anger to ensure it works in both cases.\nTarget answer = no", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nReview text: '''{review}'''\n\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "86e25b62-c452-45c6-bac3-f636ed3b902d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q4) Extract the item purchased and the company name, return as JSON format\nTarget answer = Item[lamp], Brand[Lumina]", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nReview text: ```{review}```\n\"\"\"\n\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "3fa8501c-0576-494b-b077-b1e8cba098fa"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q5) Can you combine 3-6 in a single prompt and return JSON with: Sentiment (negative or positive), Anger (yes/no), Product, Company\nTarget answer = Sentiment[positive], Anger[false], Item[lamp], Brand[Lumina]", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nReview text: '''{review}'''\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "f2b705b5-b960-459c-83b6-a5c9d302da82"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "---", "metadata": {}}, {"cell_type": "code", "source": "# Product Review for Questions  6 - 8\nreview = \"\"\"Got this panda plush toy for my daughter's birthday, \\\nwho loves it and takes it everywhere. It's soft and \\ \nsuper cute, and its face has a friendly look. It's \\ \na bit small for what I paid though. I think there \\ \nmight be other options that are bigger for the \\ \nsame price. It arrived a day earlier than expected, \\ \nso I got to play with it myself before I gave it to her.\"\"\"", "metadata": {"id": "60402785-e86e-4aaa-a827-4beaef0599d0"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q6) summarize the following product review\nExample summary = My daughter loves it!  It's soft and  super cute, and its face has a friendly look. It's  a bit small for what I paid though.", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nReview: ```{review}```\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "787d9380-f282-402d-a4b2-f5357215733c"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q7) Summarize the same product review from the perspective of the shipping department\nExample summary = It arrived a day earlier than expected, so I got to play with it myself before I gave it  to her. ", "metadata": {}}, {"cell_type": "code", "source": "#concise wrt feedback shipping\nprompt = f\"\"\"\nReview: ```{review}```\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "c1af3888-89a6-44e8-994b-a75a47a6b95d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "#### Q8) Summarize the review from the perspective of pricing and value\nExample summary = It's a bit small for what I paid though. I think there might be other options that are bigger for the same price", "metadata": {}}, {"cell_type": "code", "source": "#feedback pricing works - concise\nprompt = f\"\"\"\nReview: ```{review}```\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "2b64288b-f5b9-4109-9061-6adcb19250d1"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "---", "metadata": {}}, {"cell_type": "markdown", "source": "#### Q9)\tPII removal. Given the following email, write a prompt to remove the PII (eg names, emails etc) (Hint: you may need to use 1-2 shot technique)", "metadata": {}}, {"cell_type": "code", "source": "email = \"\"\"\nHi John,\\\n\nI'm writing to you because I noticed you recently purchased a new car. I'm a salesperson\\\nat a local dealership (Cheap Dealz), and I wanted to let you know that we have a great deal on a new\\\ncar. If you're interested, please let me know.\\\n\nThanks,\\\n\nJimmy Smith\\\n\nPhone: 410-805-2345\\\nEmail: jimmysmith@cheapdealz.com\\\n\"\"\"", "metadata": {"id": "a3a32c79-62c0-4e93-b89a-891f9142f42d"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "Hint - use prompt template or manually construct the prompt with f strings (look up in documentation if unsure)", "metadata": {}}, {"cell_type": "code", "source": "prompt = f\"\"\"\nInput:\n{email}\n\nOutput:\n\"\"\"\nresponse = send_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "cdb95431-ce04-4968-bc1f-3c8bf8df4d9e"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "---", "metadata": {}}, {"cell_type": "markdown", "source": "#### Q10) Basic inference: A patients a1c level determines their diabetes status, the rules are as follows:\n\n - less than 5.7 no diabetes\n - between 5.7 and 6.5 pre-diabetes\n - greater than 6.5 diabetic.\n\nWrite a prompt to return just the diabetes status from the following 3 test cases:\n\n1)\tThe patients a1c is 5.5 which is good considering his other risk factors.\n2)\tFrom the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\n3)\tShe mentioned her A1c is 8 according to her blood work about 3 years ago.\n\nBonus 1: How could you improve the inference given the other information in the sentences?\n\nBonus 2: how would you approach extracting the diabetes status based on patient notes without A1C values and what would you need to watch out for? (hint: maybe they are talking about family history of disease or other complications)\n", "metadata": {}}, {"cell_type": "code", "source": "record1 = \"The patients a1c is 5.5 which is good considering his other risk factors.\"\nrecord2 = \"From the last lab report I noted the A1c is 6.4 so we need to put her on Ozempic.\"\nrecord3 = \"She mentioned her A1c is 8 according to her blood work about 3 years ago.\"", "metadata": {"id": "e45a58a7-8d1d-4569-8e80-19c10c06f5d4"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#Q10 ENTER YOUR MODEL PARAMS HERE - MAKE SURE IT WORKS WITH ALL 3 EXAMPLES ABOVE\nprompt = f\"\"\"\n'''{record1}'''\n\"\"\"\n\nsend_to_watsonxai(prompts=[prompt])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "95fb7457-4f42-4d43-bff2-4d71607ed0b0"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "#This example derived from asking the model for the criteria first then copying the output into the prompt, we can change output to just \"answer yes or no\"\nprompt2 = f\"\"\"\n```{record2}```\n\"\"\"\n\nsend_to_watsonxai(prompts=[prompt2])\n# Remember to try changing the model and/or using non-default parameters to achieve your goal when prompting isn't enough\n# response = send_to_watsonxai(prompts=[prompt], model_name=\"google/flan-ul2\", decoding_method=\"greedy\", max_new_tokens=100,\n#                              min_new_tokens=30, temperature=1.0, repetition_penalty=2.0)", "metadata": {"id": "7578c36d-297d-4ca3-afcd-3d1ba3170261"}, "outputs": [], "execution_count": null}]}