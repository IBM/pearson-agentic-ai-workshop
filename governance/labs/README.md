# 🔬 AI Governance Hands-on labs

AI Governance encompasses three pillars:

- **Lifecycle Governance**
- **Risk Management**
- **Regulatory Compliance**


There's two labs touching on different aspects of these pillars:

--- 
### ⛑️ [Lab 1: Guardrails and monitoring](monitoring-and-guardrails/README.md)
In this lab, María, an AI Engineer working for ABC health. She is building an AI application to help employees answer questions on their benefits. However, she's afraid of many potential risks related to Generative AI, namely generation of harmful contents, hallucinations, toxity, confidence, among others. Additionally, she's looking for ways to automate the process of evaluating different LLMs, prompts, and techniques.

### ⚠️ [Lab 2: Risk and compliance](risk-and-compliance/README.md)
As organizations increasingly rely on AI-driven decision-making, ensuring trust, compliance, and ethical integrity of models is crucial. At TechCorp Inc., the risk and compliance team faced growing pressure to govern AI models end-to-end—from inception to incident remediation. Manual checks, siloed responsibilities, and lack of visibility into model behavior increased regulatory exposure and audit fatigue.

### 👥 Cater to your audience
Depending on the audience you might want to pick and choose an entire lab or parts of it.

👷🏻‍♂️ If there's mostly AI Engineers or Data Scientists in the room, [Lab 1: Guardrails and monitoring](monitoring-and-guardrails/README.md) would suit you best.

💼 If there's mostly business line folks, or Risk/Compliance teams, [Lab 2: Risk and compliance](risk-and-compliance/README.md) might work best.
